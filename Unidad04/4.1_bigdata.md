# Tecnologías Asociadas al IdC



## Datos masivos (Big Data)



Big Data, Macrodatos, datos masivos o a gran escala hace referencia a un gran conjunto de datos muy complejos que son tratados de manera especial para poder extraer información valiosa.

La cantidad de datos es tal que supera la capacidad del software convencional para ser capturados, administrados y procesados en un tiempo razonable. 

El término Big data lo hizo popular el Dr. En ciencias de la computación John Mashey.





### Ejemplos de datos masivos y complejos



*   El universo digital mide approx 40 zettabytes, ( $4.72236648 \times 10^{22}$)

*   Historiales de navegación
*   Mapas multibanda georeferenciados. 
*   Datos recolectados por sensores en meteorología
*   Recopilación de datos de las personas en ámbitos turísticos, salud.
*   Recopilación de comportamiento de compras en internet (retail)
*   Registro de logs para detectar y reconocer fallas mas frecuentes en los sistemas informáticos.
*   Datos de colisión del LHC (Gran colisionador de hadrones)  (aproximadamente 25 petabytes)https://es.wikipedia.org/wiki/Gran_colisionador_de_hadrones
*   Open Street maps (800 Gb)





El volumen de datos en ciertas áreas, limita su análisis como en la genómica, análisis de redes (redes sociales, conectómica) meteorología.



![Análisis de redes complejas, una herramienta para el diagnóstico y ...](figures/4.1_bigdata/images.jpeg)

La capacidad tecnológica per cápita a nivel mundial para almacenar datos se dobla aproximadamente cada cuarenta meses desde los [años 1980](https://es.wikipedia.org/wiki/Años_1980).[14](https://es.wikipedia.org/wiki/Macrodatos#cite_note-HilbertLopez20112-14)



Los sistemas de gestión de base de datos relacionales tienen dificultades tratando macrodatos con información estructurada y no estructurada de diversa naturaleza.



### Soluciones

*   Software de procesamiento masivamente paralelo MapReduce.
*   Gestores de base de datos Not Only SQL.



Big Data usa estadísticas inferenciales y conceptos de identificación de sistemas no lineales,[28](https://es.wikipedia.org/wiki/Macrodatos#cite_note-28) para inferir leyes (regresiones, relaciones no lineales y efectos causales) a partir de grandes conjuntos de datos con baja densidad de información, con la finalidad de revelar relaciones y dependencias, o para realizar predicciones de resultados y comportamientos.



**Ejemplo de estadística inferencial aplicada a la clasificación de uso de suelo.** Un modelo creado con el 10% de la información se puede inferir con cierta precisión el 90% restante 

![Captura de Pantalla 2020-04-21 a la(figures/4.1_bigdata/Captura de Pantalla 2020-04-21 a la(s) 13.03.53.png) 13.03.53](../../../../Desktop/Captura de Pantalla 2020-04-21 a la(s) 13.03.53.png)





Uno de los retos es la organización, adquisición y administración de estos datos.



### Captura de los datos

*   Generados por las propias personas en la web. 
*   Transacciones. 
*   Rastreo de la navegación por internet
*   Consultas en la web
*   Datos obtenidos a través de M2M *
*   Datos biométricos
*   Imágenes satelitales
*   Geografía: Datas georeferenciados 



### Transformación

*   Se refiere a estandarizar los datos recogidos de diferentes fuentes con plataformas *Extract, Transform and Load*.
*   Es necesario para postprocesar los datos, limpiarlos, corregirlos, usarlos, presentarlos etc...



### Almacenamiento

*   Se requiere un sistema de almacenamiento mucho mas flexible debido a la heterogeneidad de los datos. Se asume que los datos de diferentes fuentes pueden ser estructurados, semiestructurados o no estructurados, lo que dificulta el uso de base de datos relacionales. Una alternativa es el uso de bases de datos not Only SQL (NoSQL)

**Grupos de base de datos NoSQL**

Existen 4 grandes grupos:

1.  **Almacenamiento clave-valor**. 
    *   Los datos se almacenan en algo parecido a un diccionario de datos utilizando la tupla llave-valor (llave única). 
    *   Los datos no necesariamente estan relacionados y se asume independencia. Ejemplo CassandraDB. http://cassandra.apache.org/doc/latest/architecture/dynamo.html
    *   Son muy buenos realizando operaciones simples en base de datos muy grandes.  ejemplo: Como la consulta de un perfil de un usuario de algun servicio o recuperar datos que han sido calculados con anterioridad.

2.  **Basados en documentos:** 
    *   Soportan datos semiestructurados  y se pueden hacer consultas sobre ellos. 
    *   Los datos se llaman documentos y pueden tener formato XML, JSON, Binary JSON o algún otro. 
    *   Ejemplo de manejadores NoSQL que soportan estos tipos de datos son CouchDB y MongoDB. 
3.  **Almacenamiento orientado a columna:**.
    *   Se parece al documental. 
    *   Es fácil escalar horizontalmente, gregando atributos y objetos nuevos a cada registro de info asociados a una clave. 
    *   Ejemplo Hyper Table, HBase.
4.  **Almacenamiento en grafo:**
    *   Basado en teoría de grafos, la información son representados con nodos y sus relaciones con aristas. Idóneo para almacenar y analizar redes sociales, redes de citas de artículos científicos, o cualquier otra información que de manera natural pueda representarse a manera de grafos. 
    *   Sistemas Gestores de bases de datos No Relacionales de ejemplo que soportan este tipo de estructura son Cypher, SPARQL, SPASQL.



### Análisis de datos

Para el análisis de datos se encuentran un gran colección de algoritmos provenientes de aprendizaje automático, como redes neuronales, máquinas soporte de vectores, algoritmos de agrupación entre otros. Estos algoritmos sirven para: 

*   Encontrar asociaciones entre variables asumiendo causalidad (ejemplo, redes neuronales, máquina de soporte de vectores (SVM)).
*   Minería de datos. (Búsqueda de patrones)
*   Agrupación (k-means).
*   Análisis de texto. (Técnicas de procesamiento de lenguaje natural. Expresiones regulares, n-gramas)



### Visualización de datos

*El mundo es complejo, dinámico, multidimensional, el papel es estático y plano. ¿Cómo vamos a representar la rica experiencia visual del mundo en la mera planicie?-Edward Tufte*, Profesor de evidencia estadística y diseño de información y de interfaces.

El primer reto es presentar datos complejos multidimensionales en grandes cantidades en un espacio acotado y bidimensional.

Aplicación de ejemplo: Cromogram: un sistema de representación creado por [IBM](https://es.wikipedia.org/wiki/IBM) que muestra macrodatos que consisten en las ediciones de Wikipedia realizadas por el [bot](https://es.wikipedia.org/wiki/Bot) [Pearle](https://es.wikipedia.org/w/index.php?title=Pearle&action=edit&redlink=1). Su visualización más racional aparece acompañada de colores y posiciones en su representación.

![img](figures/4.1_bigdata/Viegas-UserActivityonWikipedia.gif)





Agrupación de datos multidimencionales con mapas auto-organizados

![Captura de Pantalla 2020-04-21 a la(figures/4.1_bigdata/Captura de Pantalla 2020-04-21 a la(s) 13.32.05.png) 13.32.05](../../../../Desktop/Captura de Pantalla 2020-04-21 a la(s) 13.32.05.png)





![Captura de Pantalla 2020-04-21 a la(figures/4.1_bigdata/Captura de Pantalla 2020-04-21 a la(s) 13.31.51.png) 13.31.51](../../../../Desktop/Captura de Pantalla 2020-04-21 a la(s) 13.31.51.png)

![Captura de Pantalla 2020-04-21 a la(figures/4.1_bigdata/Captura de Pantalla 2020-04-21 a la(s) 13.31.59.png) 13.31.59](../../../../Desktop/Captura de Pantalla 2020-04-21 a la(s) 13.31.59.png)



Que otros algorimos y plataformas existen?



### Aplicaciones de Big Data

1.  Industria

2.  Gobierno 

    1.  (https://www.inegi.org.mx/app/animotuitero/#/app/multiline)
    2.  https://u-gob.com/inegi-presenta-su-nueva-herramienta-de-big-data-para-medir-estado-de-animo-en-twitter/

3.  Empresas

4.  Desarrollo internacional

5.  Medios?

6.  Seguros

7.  Deportes

8.  Finanzas

9.  Marketing y ventas Investigación

10.  Medicina

11.  Muestreo. (como muestrear para Inferir por medio del estudio de un subconjunto de datos. Seleccion de datos para estimar características de la población completa)

12.  Defensa y seguridad. (proteccion de ciber ataques)



### Críticas a Big Data

Se hacen suposiciones muy fuertes sobre propiedades matemáticas que pueden no reflejar el comportamiento de los datos en la realidad como: 

1.  cuando se asume que los datos tienen cierta distrubución, (e.g., distribución normal (gaussiana),  uniforme, etc.).  (Snijders, Matzat y Reips). 
2.  Suposición de que correlación implica causalidad.

Hay dos opiniones contradictorias respecto al uso, manejo y desarrollo de algoritmos para procesar Big Data.

Por un lado, Mark Graham dice que los datos siempre deben contextualizarse en cada ámbito de estudio. Ejemplo: si los datos consisten en series de tiempo lineales, caóticas. Imágenes. Información espacial, espacio temporal etc..., información geográfica.

Por otro lado Chris Anderson opina lo contrario. El análisis de big data será meramente empírico importando poco la naturaleza de los datos.



## Relación de Big Data con Internet de las cosas (IdC, IoT)

*Notas de *  de "Big Data for Internet of Things: A Survey" de Mouzhi Ge et al. Las referencias mostradas en esta parte son las relacionadas a este artículo.



Se refiere en la adquisición de macro datos por medio de redes de comunicaciones y equipos de cómputo que comunican máquinas. (M2M).

*   El desarrollo de big data ha estado aislado de IdC en diferentes dominios. 
*   El mutuo entendimiento IdC -  BigData data es importante para avanzar en la investigación y desarrollo de esta tecnología. Por lo tanto es importante revisar como BigData se asocia con IdC.
*   Existen tecnologías clave para manejo de BigData en diferentes dominios de IdC,  que pueden ser rehusados.

Ya que IdC conecta una gran variedad de dispositivos a través de internet, es importante el desarrollo de tecnología que soporte el desarrollo de estos dispositivos.

La implementación de aplicaciones de Internet de las cosas tiene algunos retos propios a resolver como el  recoger y analizar diferentes tipos de datos (heterogéneos) y en grandes cantidades del mundo real.

La extracción de información relevante de IdC puede ser utilizada para mejorar y enriquecer la vida diaria con aplicaciones orientadas a diferentes contextos.

==El contexto== es la información que es usada para caracterizar la situacion de entidades y esta es relevante en su interacción en tiempo real. Por lo regular tiene atributos o características como ubicación, tiempo, estado de las personas, variables ambientales. Aquí IdC es muy importante para alimentar de datos contextuales a las entidades.

Una entidad puede ser por ejemplo cualquier objeto, una persona, lugar.

IdC se convierte en una importante  plataforma para capturar y procesar estos datos contextuales en mucho volumen, variedad y velocidad. Esto hace que esta rama del big data sea retadora.

Para distinguir que tipo de datos son Big Data, está tiene 5 características (+1) fundamentales:

1.  Volumen
2.  Velocidad
3.  Valor
4.  Variabilidad
5.  Veracidad
6.  Variedad. 



![The 5V of Big Data Characteristics | Download Scientific Diagram](figures/4.1_bigdata/The-5V-of-Big-Data-Characteristics.png)





En [6] sugiere otras caracteristicas como 

3.  viscosidad (latencia en la transmisión de datos)
4.  viralidad (velocidad de transmisión de los datos recibidos y enviados desde varias fuentes)
5.  visualizacion (interpretacion de datos e identificación de la info mas relevante.)

Para poder hacer este tipo de datos con estas características utilizables se emplean modelos y metodologías de Aprendizaje automático (https://es.wikipedia.org/wiki/Aprendizaje_automático), que  metodologías computacionales útiles para encontrar patrones en grandes datos. Estas metodologías por lo regular asumen causalidad. 26. (https://es.wikipedia.org/wiki/Macrodatos#cite_note-26)



### Servicios que nacen de la Fusion de BigData - IdC

BigData - IdC propicia el desarrollo de servicios para muchos sistemas complejos como ciudades inteligentes.

Big Data ha abierto nuevas oportunidades de aplicación para industria y academia.

En el artículo de "Big Data for Internet of Things: A Survey" de Mouzhi Ge et al,  se revisaron 117 artículos que aplican big data en 8 dominios según Bahga and Madisetti [65].

1.  Salud
2.  Energía
3.  Transporte
4.  Edificios Inteligentes (building automation)
5.  Ciudades Inteligentes
6.  Agricultura
7.  Industria
8.  Milicia



La mayoría de los dominios mencionados necesitan **tecnología robusta** para lidiar con la disponibilidad de los objetos y seguridad para que los datos y la comunicación no sea vulnerada.[65, 66, 67, 68].

Por ejemplo, en áreas de la salud uno de los retos es reunir y analizar información médica en tiempo real para minimizar las limitaciones de los tratamientos médicos tradicionales. [11, 12]. En este contexto se ha encontrado que las plataformas en la nube son populares para guardar y analizar flujo de datos medicos.

En energía, Big data se ha encontrado que utiliza algoritmos inteligentes de distribución de electricidad aprovechando los recursos renovables en sistemas eléctricos de potencia, control de la red de la distribución de energía.[16, 17]

En Transporte, IdC -BigData ayuda en la planeación de rutas y desarrolla las aplicaciones para vigilancia, emergencia, control de tráfico, detección de anomalías, predicción de tráfico y minimización de contaminantes. 

Automatización de edificios: La integración de un gran número de dispositivos IdC en edificios , permiten monitorear todos los días actividades de los ciudadanos as como predecir su comportamiento. Esto se da al poder reunir información sensible a tiempo que describe de manera muy detallada interacciones entre humanos y máquinas [32,33,34]. Esta información es importante para optimizar servicios en edificios inteligentes, como seguridad, control de acceso, video digital, detección de intrusos, detección de fuego, servicios de ambientes internos o control de iluminación.

Ciudades Inteligentes: La visión de Ciudades inteligentes es mejorar el estilo de vida proveyendo mejoras en el servicio publico como, estacionamientos, limpieza de la ciuad, manejo de basura, iluminación en calles, control de emergencias  [35, 36, 37]. 



## Procesos de Big data y ciclo de vida 



**Propuesta de Gandomi: **

Gandomi 2015 [70] han dividido las etapas del tratamiento de big data en: 

1.  **Manejo de datos:** recolectar y guardar datos así como limpiar y recuperar datos para la preparación de su análisis. 
2.  **Analítica de datos**: Trata de la extracción de pistas de los datos. Contempla la modelización, análisis e interpretación.
    1.  Modelización , 
    2.  Análisis 
    3.  Interpretación.

**Propuesta de Paakkonen et al.** 2015 [72] 

Proponen una arquitectura de Big Data de referencia que enfocado a la fuente de datos y su almacenamiento como la entrada e infraestructura de los datos. 

El proceso del tratamiento de los datos son 5 básicos

1.  **Adquisición** de datos. (Datos recolectados por sensores)
2.  **Carga** de datos. (Cargar datos a memoria para ser analizados)
3.  **Preprocesamiento**. (Reparar datos.)
4.  **Procesamiento**. (Modelización)
5.  **Análisis**. (Análisis estadístico, visual)



**Propuesta de Khan et al. 2014 [71] **  

1.  **Recolección** de datos
2.  **Clasificación**
3.  **Análisis**
4.  **Recuperación** de datos para tomar decisiones.
5.  **Almacenamiento**
6.  **Difusión**



**Propuesta de Tsai et al 2015 [74]**

Propone que el proceso queneral debe tener dos fases

1.  **Fase de entrada**. 
    1.  Reunión de datos
    2.  Selección 
    3.  Transformación 
    4.  Analítica de datos. (reconocimiento de patrones, clustering)
2.  **Fase de salida:** 
    1.  Esta la evaluación, e intepretacion de los datos así como su presentación.



Los aspectos generales del ciclo de vida propuestos son:



1.  Almacenamiento
2.  Limpieza
3.  Analítica
4.  Visualizacion





## Notas sobre enfoques tecnológicos mas populares en diferentes dominios de IdC desde la perspectiva de Macrodatos (Big Data)

Ver Tabla 4 del Apéndice, página 49



**Deducciónes relacionadas a Big Data sobre los dominios IdC



**Almacenamiento** pagina 16

1.  Almacenamiento: en todos los dominios, el almacenamiento en la nube es la infraestructura mas aceptada debido a que es escalable y elástica [194]. 
2.  Los dominios emergentes como Ciudades Inteligentes tienen menos problemas en utilizar tecnologías mas nuevas como Bases de Datos NoSQL y prefieren contratar un servicio en la nube. Tecnologías como **CouchDB** [177] and **MongoDB** [177], Cassandra)  permiten tener siempre los reportes actualizados.



3.  Dominios mas tradicionales (con mas tiempo en existencia) como Salud y agricultura Utilizan aún base de datos relacionales aunque manejan una gran cantidad de datos ya que el cambio les genera un costo.

4.  En general  NoSQL es mas popular que las bases de datos relacionales en aplicaciones en dominios nuevos en IdC y es favorito para guardar Datos de IdC.
5.  También se observa que la industria utiliza bases de datos SQL y NoSQL debido a que se encunetran un un periodo de transición tecnológica.
6.  A pesar de que en áreas de la salud se recomienda hacer el cambio de SQL a NoSQL existe un problema de transformación de datos. La conversión de datos de una base de datos a otra de manera automatizada no es trivial y por lo tanto es un tema de investigación.

**Limpieza de datos (Cleansing)**

1.  Es necesario hacer limpieza como  prerequisito para hacer análisis e integración de datos.
2.  Integración de datos puede ser el proceso de Extraer Transformar y Cargar, y también el proceso de fusionar o agregar datos.
3.  La limpieza de datos sirve también para cuidar la calidad de los datos. Se sugiere que para poder hacer analítica de datos en IdC, los datos deben ser de alta calidad.



**Analítica **(pág 17)

1.  Para análisis,  **Hadoop** and **Spark**  son usados en los dominios  del cuidado de la salud y transporte. 
2.  MapReduce es un metodo aceptado para el análisis de datos de forma paralela de datos guardados en sistemas distribuidos.
3.  Son populares los algoritmos basados en arboles de decision en ciencias de la salud. En energía redes neuronales y mineria de asociacion de reglas.  
4.  Los algoritmos mas populares para el procesamiento de datos son los algoritmos de clustering. 
5.  Otros técnicas usadas en general son (en inglés):

*   Análisis semántico. (semantic analysis)
*   Proceso analítico de jerarquís.  (analytic hierarchy process)
*   **clustering***
*   feature extraction
*   association rule mining. Generación de reglas por ejemplo con, Lógica y lógica difusa. Operación de conjuntos.
*   **Reconocimiento de patrones (pattern recognition)***.
*   decision Tree, 
*   **Redes Neuronales (neural network)***, 
*   Redes Bayesianas (Bayesian network),
*    Mineria de patrones frecuentes (frequent pattern mining), 
*   Aprendizaje profundo (deep Learning)
*    **fuzzy logic**, 
*   rule extraction, 
*   multiple linear regression, 
*   Naive Bayes, 
*   K-nearest neighbor algorithm, 
*   contextual filtering,
*    sequence analysis, and 
*   data envelopment analysis.





**Visualización**



Visualización es llamado a veces interpretacion o presentación de datos.

No hay muchos métodos para lidiar con el procesamiento visual de datos en tiempo real.

Métodos de visualizacion prometen un futuro en el campo de la investigación de big data en IoT.

Ejemplo. Edificio del Laboratorio Nacional de visualización Avanzada  en la UNAM - Juriquilla



![IMG_4815](figures/4.1_bigdata/IMG_4815-7583366.JPG)

#### ![IMG_4815]()Tecnologías Claves infraestrucutra de



![IMG_6650 2](figures/4.1_bigdata/IMG_6650.JPG)









### Bibliografía 

M. Ge, H. Bangui, B. Buhnova, Big data for internet of things: A survey, *Future Generation Computer Systems* (2018), https://doi.org/10.1016/j.future.2018.04.053

Wikipedia, Macrodatos. https://es.wikipedia.org/wiki/Macrodatos



## Fog Computing

https://wattio.com/es/blog/que-es-el-fog-computing-/29









 











































